{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your original file and the output file\n",
        "input_file_path = '/content/Disease_script.txt'\n",
        "output_file_path = '/content/Trimmed_Filtered_Disease_script.txt'\n",
        "\n",
        "# Function to process the file and extract 50% of sentences for the first 500 diseases\n",
        "def process_file(input_file, output_file):\n",
        "    with open(input_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # We now consider only the first 500 diseases, each with 10 sentences, thus 5000 lines in total\n",
        "    lines = lines[:5000]\n",
        "\n",
        "    # Assuming each disease has 10 sentences, we take 5 out of 10 for each\n",
        "    processed_lines = []\n",
        "    for i in range(0, len(lines), 10):  # Iterate through the file 10 lines at a time\n",
        "        selected_lines = lines[i:i+10][:5]  # Select the first 5 lines out of each set of 10\n",
        "        processed_lines.extend(selected_lines)\n",
        "\n",
        "    # Write the selected lines to a new file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.writelines(processed_lines)\n",
        "\n",
        "# Call the function with the paths to your input and output files\n",
        "process_file(input_file_path, output_file_path)\n",
        "\n",
        "print(\"Processing completed. The trimmed and filtered sentences are written to\", output_file_path)\n"
      ],
      "metadata": {
        "id": "frJHZEaTckEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install requests\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import base64\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Function to synthesize text and save to respective folders\n",
        "def synthesize_text_with_api_key(text, voice_name, language_code, gender, output_file, api_key):\n",
        "    url = \"https://texttospeech.googleapis.com/v1/text:synthesize\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json; charset=utf-8\"\n",
        "    }\n",
        "    data = {\n",
        "        \"input\": {\"text\": text},\n",
        "        \"voice\": {\n",
        "            \"languageCode\": language_code,\n",
        "            \"name\": voice_name,\n",
        "            \"ssmlGender\": gender\n",
        "        },\n",
        "        \"audioConfig\": {\n",
        "            \"audioEncoding\": \"LINEAR16\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, params={\"key\": api_key}, json=data)\n",
        "    if response.status_code == 200:\n",
        "        audio_content = response.json()['audioContent']\n",
        "        with open(output_file, \"wb\") as out:\n",
        "            out.write(base64.b64decode(audio_content))\n",
        "        print(f\"Generated audio file: {output_file}\")\n",
        "    else:\n",
        "        print(f\"Error in generating audio file for {output_file}: {response.text}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directories for male and female voices\n",
        "os.makedirs('male_voices', exist_ok=True)\n",
        "os.makedirs('female_voices', exist_ok=True)\n",
        "\n",
        "# Your API key\n",
        "api_key = \"AIzaSyCmZgZ0eSs6xIp-fymgw2v5sj-0dCiB2RA\"\n",
        "\n",
        "# Define different voices and accents\n",
        "# Define different voices and accents\n",
        "voices = [\n",
        "    {\"voice_name\": \"en-GB-Wavenet-A\", \"language_code\": \"en-GB\", \"gender\": \"MALE\", \"folder\": \"male_voices\"},\n",
        "    {\"voice_name\": \"en-GB-Wavenet-F\", \"language_code\": \"en-GB\", \"gender\": \"FEMALE\", \"folder\": \"female_voices\"},\n",
        "    #{\"voice_name\": \"en-AU-Wavenet-A\", \"language_code\": \"en-AU\", \"gender\": \"MALE\", \"folder\": \"male_voices\"},\n",
        "    #{\"voice_name\": \"en-AU-Wavenet-C\", \"language_code\": \"en-AU\", \"gender\": \"FEMALE\", \"folder\": \"female_voices\"},\n",
        "    {\"voice_name\": \"en-US-Wavenet-A\", \"language_code\": \"en-US\", \"gender\": \"MALE\", \"folder\": \"male_voices\"},\n",
        "    {\"voice_name\": \"en-US-Wavenet-F\", \"language_code\": \"en-US\", \"gender\": \"FEMALE\", \"folder\": \"female_voices\"},\n",
        "    # Add more voices and accents as needed\n",
        "]\n",
        "\n",
        "\n",
        "# Initialize lists for audio paths and text data\n",
        "audio_paths = []\n",
        "text_data = []\n",
        "\n",
        "# Read sentences from file\n",
        "#with open('/content/Filtered_Disease_script.txt', 'r') as file:\n",
        "with open('/content/Trimmed_Filtered_Disease_script.txt', 'r') as file:\n",
        "    sentences = file.readlines()\n",
        "\n",
        "print(\"Starting text-to-speech synthesis...\")\n",
        "\n",
        "# Loop over sentences and synthesize speech\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for voice in voices:\n",
        "        unique_id = f\"{i}_{voice['voice_name']}\"\n",
        "        output_file = f'{voice[\"folder\"]}/output_{unique_id}.wav'\n",
        "        synthesize_text_with_api_key(sentence.strip(), voice[\"voice_name\"], voice[\"language_code\"], voice[\"gender\"], output_file, api_key)\n",
        "        audio_paths.append(f\"{unique_id} /content/{output_file}\")\n",
        "        text_data.append(f\"{unique_id} {sentence.strip()}\")\n",
        "\n",
        "print(\"Text-to-speech synthesis completed. Writing audio paths and text data to files...\")\n",
        "\n",
        "# Write the audio paths and text data to files\n",
        "with open('audio_paths.txt', 'w') as file:\n",
        "    for line in audio_paths:\n",
        "        file.write(f\"{line}\\n\")\n",
        "\n",
        "with open('text.txt', 'w') as file:\n",
        "    for line in text_data:\n",
        "        file.write(f\"{line}\\n\")\n",
        "\n",
        "print(\"Files written. Zipping folders...\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kVgFVvUwZz-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a zip file\n",
        "zipf = zipfile.ZipFile('voices_final_trimmed_2.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "for root, dirs, files in os.walk('male_voices'):\n",
        "    for file in files:\n",
        "        zipf.write(os.path.join(root, file))\n",
        "for root, dirs, files in os.walk('female_voices'):\n",
        "    for file in files:\n",
        "        zipf.write(os.path.join(root, file))\n",
        "zipf.close()\n",
        "\n",
        "print(\"Zipping complete. Uploading to Google Drive...\")\n",
        "\n",
        "# Specify your Google Drive path where you want to save the zip file\n",
        "drive_path = '/content/drive/My Drive/Projects/AudioFiles_final/'  # Modify this path\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Copy the zip file to Google Drive\n",
        "destination_path = os.path.join(drive_path, 'voices_final_trimmed_2.zip')\n",
        "shutil.copy('voices_final_trimmed_2.zip', destination_path)\n",
        "\n",
        "print(f\"Upload complete. File saved to Google Drive at: {destination_path}\")\n"
      ],
      "metadata": {
        "id": "GLDz--UW-UCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}