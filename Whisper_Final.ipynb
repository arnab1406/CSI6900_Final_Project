{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHgnZR-jprjJ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install jiwer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "LyrCsRmEp959"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Projects/AudioFiles_final/voices_final_trimmed_2.zip\" -d \"/content\"\n"
      ],
      "metadata": {
        "id": "sYMJLQNUqJIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"small\")\n"
      ],
      "metadata": {
        "id": "NO8CTv7tqihl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to transcribe audio\n",
        "def transcribe_audio(audio_path):\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]"
      ],
      "metadata": {
        "id": "lRCooEaUs-Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of loading and parsing the audio_paths\n",
        "with open('/content/audio_paths_file.txt', 'r') as f:\n",
        "    # Assuming the full path is the second part after splitting by space\n",
        "    audio_paths = [line.strip().split(' ')[1] for line in f.readlines()]\n",
        "\n",
        "\n",
        "with open('/content/text_file.txt', 'r') as f:\n",
        "    texts = [line.strip() for line in f.readlines()]\n"
      ],
      "metadata": {
        "id": "NLsc-xcbs_vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer, cer\n",
        "\n",
        "# Initialize lists to hold detailed results for each file\n",
        "detailed_results = []\n",
        "\n",
        "# Continue from your previous code...\n",
        "total_wer, total_cer = 0, 0\n",
        "num_files = len(audio_paths)\n",
        "\n",
        "# Transcribe and calculate metrics, storing detailed results\n",
        "for i, audio_path in enumerate(audio_paths):\n",
        "    true_text = texts[i]\n",
        "    predicted_text = transcribe_audio(audio_path)  # Utilize the full path directly\n",
        "    file_wer = wer(true_text, predicted_text)\n",
        "    file_cer = cer(true_text, predicted_text)\n",
        "    total_wer += file_wer\n",
        "    total_cer += file_cer\n",
        "    detailed_results.append({\n",
        "        'Reference': true_text,\n",
        "        'Predicted': predicted_text,\n",
        "        'WER': file_wer,\n",
        "        'CER': file_cer\n",
        "    })\n",
        "    print(f\"Processed {i+1}/{num_files} files.\")\n",
        "\n",
        "# Calculate averages\n",
        "avg_wer = total_wer / num_files * 100\n",
        "avg_cer = total_cer / num_files * 100\n",
        "\n",
        "# Output file path\n",
        "results_file_path = '/content/drive/MyDrive/transcription_evaluation_detailed_results_whisper.txt'\n",
        "\n",
        "# Write detailed results to the file\n",
        "with open(results_file_path, 'w') as f:\n",
        "    f.write(f\"Dataset: /content/output_data_directory/eval_dataset_vosk\\n\")\n",
        "    f.write(f\"WER: {avg_wer:.2f}%, CER: {avg_cer:.2f}%\\n\\n\")\n",
        "    for result in detailed_results:\n",
        "        f.write(f'Reference: \"{result[\"Reference\"]}\"\\n')\n",
        "        f.write(f'Predicted: \"{result[\"Predicted\"]}\"\\n')\n",
        "        f.write(f'WER: {result[\"WER\"]*100:.2f}%, CER: {result[\"CER\"]*100:.2f}%\\n\\n')\n",
        "\n",
        "print(f\"Results saved to {results_file_path}\")\n"
      ],
      "metadata": {
        "id": "m-gLAWcqt75w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n"
      ],
      "metadata": {
        "id": "3OPmH1ACyspb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your new folder path and name\n",
        "new_folder_path = '/content/drive/MyDrive/TranscriptionResultsWhisper'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(new_folder_path):\n",
        "    os.makedirs(new_folder_path)\n",
        "    print(f\"Created folder: {new_folder_path}\")\n",
        "else:\n",
        "    print(f\"Folder already exists: {new_folder_path}\")"
      ],
      "metadata": {
        "id": "iK8lsbfLSyzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# Define the path to the new results file location\n",
        "new_results_file_path = os.path.join(new_folder_path, 'transcription_evaluation_detailed_results_whisper.txt')\n",
        "\n",
        "# Move the file\n",
        "shutil.move(results_file_path, new_results_file_path)\n",
        "\n",
        "print(f\"Results moved to {new_results_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2IM1JMgry8L1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}